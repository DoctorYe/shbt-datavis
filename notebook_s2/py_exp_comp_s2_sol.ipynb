{
 "metadata": {
  "name": "",
  "signature": "sha256:b904e9761396ee29874d6645a85b929d8e14aec402457af3c423eb813eefe3ff"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Exploratory Computing with Python\n",
      "\n",
      "## Statistics Notebook 2: Continuous random variables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook we deal with continuous distributions. In the first half of the notebook we analyze data that we generate ourselves. In the second half we start looking at measured data.\n",
      "\n",
      "The most common probability distribution is probably (no pun intended) the Normal distribution. Random numbers from a Normal distribution may be generated with the `standard_normal` function in the `random` subpackage of `numpy`. The numbers are drawn from a \"standard\" Normal distribution, which means a Normal distribution with mean 0 and standard deviation 1. The mean and standard deviation of a dataset can be computed with the functions `mean` and `std`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython.html.widgets as widgets\n",
      "from IPython.html.widgets import interact, interactive, fixed\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import mpld3\n",
      "mpld3.enable_notebook()\n",
      "\n",
      "def axvline(val, **kwargs):\n",
      "    ax = plt.gca()\n",
      "    ylim = ax.get_ylim()\n",
      "    return plt.plot([val, val], ylim, **kwargs)\n",
      "\n",
      "plt.axvline = axvline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@interact(N=(1, 1000))\n",
      "def plot_mean_and_std(N):\n",
      "    data = np.random.standard_normal(N)  # Array with 100 values\n",
      "    print('mean of data: ', np.mean(data))\n",
      "    print('standard deviation of data: ', np.std(data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the mean and standard deviation are not exactly equal to 0 and 1, respectively. These are, after all, only estimates of the true underlying mean and standard deviation. These estimates are called the sample mean and sample standard deviation (of 100 numbers drawn from a Normal distribution). Run the above code several times. Each time, a new set of 100 random numbers is drawn, with a slightly different mean and standard deviation. We'll get back to that later. \n",
      "\n",
      "To generate numbers from a Normal distribution with mean $\\mu$ and standard deviation $\\sigma$, draw numbers from the standard Normal distribution, multiply all values by $\\sigma$ and then add $\\mu$ (see end of Section 7.4 in Statistics book by Dekking et al.)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@interact(N=(1, 1000), mu=(-100, 100))\n",
      "def plot_mean_and_std(N, mu):\n",
      "    data = np.random.standard_normal(N) + mu  # Array with 100 values\n",
      "    print('mean of data: ', np.mean(data))\n",
      "    print('standard deviation of data: ', np.std(data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When you obtain a new data set, one of the first things to do is to look at the data. One way to do that is to draw a histogram. For a histogram, you count how many data points fall within a certain interval. For example, how many data points are within 5 and 6. These intervals are called bins. The bar graph of the number of data points in each bin is called a histogram. The function to compute and plot a histogram is called `hist`. The simplest way of plotting a histogram is to let `hist` decide what bins to use; the default number of bins is `nbin=10`; `hist` even figures out where to put the limits of the bins. The `hist` function creates a histogram graph and returns a tuple of three items. The first item is an array of length `nbin` with the number of data points in each bin. The second item is an array of length `nbin+1` with the limits of the bins. The third item is a list of objects that represent the bars of the histogram; we won't use this last item here. Note that with this size of a data base (100 data points), the histogram doesn't look too much like the typical bell-shaped curve of a Normal distribution, even though the data points are actually drawn from a real Normal distribution."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@interact(N=(10, 1000), mu=(-100, 100))\n",
      "def plot_mean_and_std(N, mu):\n",
      "    data = np.random.standard_normal(N) + mu\n",
      "    a = plt.hist(data)\n",
      "    plt.xlabel('bins')\n",
      "    plt.ylabel('number of data points')\n",
      "    print('mean of data: ', np.mean(data))\n",
      "    print('standard deviation of data: ', np.std(data))\n",
      "    print('number of data points in each bin: ',a[0])\n",
      "    print('limits of the bins: ',a[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see from the previous example (you can run it several times), the limits of the bins are not chosen as nice numbers: `hist` takes the minimum and maximum value of the data and divides it in `nbin` equal intervals. Alternatively, you can specify the number of bins with the `bins` keyword, and the range (minimum and maximum limits of the bins) with the `range` keyword. If data values are outside this range (such as outliers), they are ignored. In the code below, 12 bins are chosen equally spaced from 0 to 12. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = 3 * np.random.standard_normal(100) + 6.\n",
      "a = plt.hist(data, bins = 12, range = (0,12))\n",
      "print 'number of data points in each bin: ',a[0]\n",
      "print 'limits of the bins: ',a[1]\n",
      "plt.xlabel('bins')\n",
      "plt.ylabel('number of data points')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A line representing the underlying normal distribution may be added as follows. First import the `norm` class from the `scipy.stats` package. Then call the `norm.pdf` function (pdf stands for probability density function) to compute the values of the normal distribution given three arguments: the $x$ values where to compute the normal distribution, the mean, and the standard deviation. Let's add the normal distribution to the histogram we just created. The one thing we have to change in the histogram is the vertical axis. In the graph above, the vertical axis shows the number of data points. We need to normalize this so that the vertical axis gives the probability that a data point lies in a bin. The histogram may be normalized by specifying the `normed = True` keyword:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm\n",
      "@interact(N=(500, 1000), mu=(-5, 5), sig=(1., 3))\n",
      "def plot_mean_and_std(N, mu, sig):\n",
      "    data = sig * np.random.standard_normal(N) + mu  # Array with N values\n",
      "    a = plt.hist(data, bins = N/10, range = (- 10, +10), normed=True)\n",
      "    x = np.linspace(-10, 10, 100)\n",
      "    y = norm.pdf(x, mu, sig) # mu=6, sig=2\n",
      "    plt.plot(x, y, 'r')\n",
      "    plt.xlabel('bins')\n",
      "    plt.ylabel('probability')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 1: <a name=\"back1\"></a>First histogram\n",
      "Generate 1000 random numbers from a Normal distribution with mean 100 and standard deviation 10. Compute and print to the screen the mean and standard deviation of your data. Create two graphs above each other using the `subplot` command (use `help(subplot)` if you forgot how to do that). In the top graph, plot a histogram using 20 bins going from 50 to 150. Note that with this size of a data set (1000 data points), the histogram starts to look a lot more like the typical bell-shaped curve of a Normal distribution. Add a red line representing the probability density function of the underlying normal distribution to the graph. In the bottom graph, draw a histogram of the cumulative distribution function, by setting the keyword `cumulative = True` (see `help(hist)` for details). For the latter graph, it may also be nice to use the `histtype = 'step'` keyword. Add a red line representing the cumulative distribution function of the underlying normal distribution to the graph using the `norm.cdf` function, which works the same as the `norm.pdf` function but computes the cumulative distribution function (cdf). Finally, make sure the xlimits are the same for both graphs. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex1answer\">Answers to Exercise 1</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Percentiles\n",
      "Another useful description of a dataset are the percentiles or quantiles. For this we consider the ordered data, that is, we order the datapoints in ascending order (so the first datapoint is the minimum of the data and the last datapoint is the maximum). The 25 percentile is the data point in the ordered data such that 25% of the data is below this datapoint (and thus 75% is above this datapoint). The percentiles of a dataset are commonly referred to as the 'empirical percentiles' as they are the percentiles of the dataset, not of the underlying distribution. The 50 empirical percentile is equivalent to the median of the data. Common intervals to look at are the 50% region around the median (also called the interquartile range or IQR), which runs from the 25 empirical percentile to the 75 empirical percentile, and the 95% region, which runs from the 2.5 empirical percentile to the 97.5 empirical percentile. Percentiles of a dataset may be computed with the `percentile` function in the `numpy` package. The first argument is the data, the second argument is a list of percentiles:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@interact(N=(50, 150), mu=(5, 15), sig=(1., 3))\n",
      "def plot_mean_and_std(N, mu, sig):\n",
      "    data = sig * np.random.standard_normal(N) + mu  # Array with 100 values\n",
      "    lower, median, upper = np.percentile(data, [2.5, 50, 97.5])\n",
      "    print('2.5 percentile: ', lower)\n",
      "    print('50 percentile: ', median)\n",
      "    print('97.5 percentile: ', upper)\n",
      "    print('95% interval: ', lower, ' to ', upper)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Expercise 2. <a name=\"back2\"></a>Lower and upper quartile\n",
      "Generate 1000 data points from a normal distribution with a mean of 20 and a standard deviation of 4. Compute the interquartile range (25%-75% range). Compute the theoretical value of the interquartile range and compare it to the interquartile range of the data. Draw a histogram of the cumulative distribution. Add red vertical lines to your graph for the 25 and 75 empirical percentiles of the data, and black vertical lines for the true 25 and 75 percentiles. Vertical lines that span the graph may be added with the `axvline` function, which takes the $x$ value of the line as an argument. To specify the color of the vertical line, use the `color` keyword argument."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex2answer\">Answers to Exercise 2</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Box-whisker plots\n",
      "Box-whisker plots (also simply referred to as boxplots) are a way to visualize the level and spread of the data. By simply looking at a boxplot, you can see whether the data is symmetric or not, and how widely the data are spread. A box-whisker plot may be created with the `boxplot` function in the `matplotlib` package as follows"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@interact(N=(400, 600), mu=(5, 15), sigma=(1,5))\n",
      "def plot_boxplot(N, mu, sigma):\n",
      "    np.random.seed(10)\n",
      "    data = sigma * np.random.standard_normal(N) + mu\n",
      "    a = plt.boxplot(data)\n",
      "    #plt.ylim((-10, 25))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `boxplot` function creates the graph and returns a lot of stuff such as 'boxes', 'caps', etc. These latter ones are handles to the different features of the graph; we will not use them here. What you see in the graph is a red line at the median of the data. The blue box spans the IQR ranging from the lower quartile (25%) to the upper quartile (75%). The whiskers are the black lines that are connected to the 50% box with the blue dashed lines. They extend to the most extreme data point within the `whis*IQR` data range, where the default value of `whis` is 1.5. Any data points falling outside the whiskers are potential outliers and are plotted as crosses. In this case there are 5 points outside the whiskers, but none are outliers. They were, after all, drawn from a Normal distribution!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Dataset of experiments on vowels\n",
      "\n",
      "It is time to start applying our statistical techniques to data obtained from acoustic recordings.\n",
      "\n",
      "A data set of acoustic analysis of vowel production is provided in the file `../data/verified_pb.data` (data courtesy: https://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/speech/database/pb/0.html). The file contains 8 columns separated by white space. The description of the columns are in the file `../data/HEADER`. The first column has the gender of the sample (`gender`), followed by: the identity (`speaker`), the phoneme number (`pid`), the phoneme (`phoneme`), the fundamental frequency in Hz (`F0`), the first formant in Hz (`F1`), the second formant in Hz (`F2`), and the third formant in Hz (`F3`)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 3. <a name=\"back3\"></a>Loading experimental data and basic operations\n",
      "Load the data in the file `../data/verified_pb.data` using the `read_table` command of the `pandas` package (refer to `notebook_wm1` for an introduction into `pandas`). Carry out the following three tasks:\n",
      "\n",
      "* Determine and report the minimum and maximum measured values of F0. \n",
      "* Determine and report the mean and standard deviation of the F1. \n",
      "* Determine and report the 2.5, 50, and 97.5 percentiles of the F3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "data = pd.read_table('../data/verified_pb.data', names=['gender', 'speaker', 'pid', 'phoneme', 'F0', 'F1', 'F2', 'F3'])\n",
      "data.head()\n",
      "# Finish this"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex3answer\">Answers to Exercise 3</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 4. <a name=\"back4\"></a>Boxplot of F0\n",
      "The fundamental frequency or F0, perceived as \"pitch\", is defined as the rate at which your vocal cords vibrate during vocalic sounds and is recorded in Hz. Compute and report the mean and standard deviation of F0, and make a box plot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now this dataset has a gender column. Make a boxplot of all the male speakers `data.gender==1`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When you look at this last boxplot, it is obvious that there are many outliers. Create a new boxplot for all the data except for the most extreme outliers, for example by making a boxplot for all F0 data below a certain value. Make sure you choose correct limits for the vertical axis, so that the whiskers are visible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex4answer\">Answers to Exercise 4</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 5. <a name=\"back5\"></a>Histogram of F0\n",
      "Now Create a histogram of F0. Add labels to the axes. Does the histogram look like a Normal distribution? If not, why, not?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex5answer\">Answers to Exercise 5</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 6. <a name=\"back6\"></a>Normal distribution for F0\n",
      "Let's try to fit a normal distribution to the F0 data. This is obviously not quite correct. Create a normalized histogram of F0. Compute the mean and standard deviation of the F0 data and plot on the same graph the Normal probability density function using these estimates of the mean and standard deviation. Now add normal probability density functions for male speakers, female speakers and children in separate figures. If you were given only F0 and asked to determine gender, who would be the easiest and hardest to separate?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex6answer\">Answers to Exercise 6</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***\n",
      "\n",
      "###Answers to the exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a name=\"ex1answer\">Answers to Exercise 1</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm\n",
      "mu = 100.0\n",
      "sig = 10.0\n",
      "data = sig * np.random.standard_normal(1000) + mu\n",
      "print('mean of data is: ', np.mean(data))\n",
      "print('standard devaiation of data is: ', np.std(data))\n",
      "plt.subplot(211)\n",
      "a = plt.hist(data, bins=20, range=(50,150), normed=True)\n",
      "x = np.linspace(50, 150, 100)\n",
      "y = norm.pdf(x, mu, sig)\n",
      "plt.plot(x, y, 'r')\n",
      "plt.xlim(50, 150)\n",
      "plt.ylabel('probability')\n",
      "plt.subplot(212)\n",
      "b = plt.hist(data, bins=20, range=(50,150), cumulative=True, histtype='step', normed=True)\n",
      "y = norm.cdf(x, mu, sig)\n",
      "plt.plot(x, y, 'r')\n",
      "plt.xlim(50, 150)\n",
      "plt.xlabel('bins')\n",
      "plt.ylabel('probability')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back1\">Back to Exercise 1</a>\n",
      "\n",
      "<a name=\"ex2answer\">Answers to Exercise 2</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mu = 20.0\n",
      "sig = 4.0\n",
      "lower_theoretical = mu - 0.675 * sig\n",
      "upper_theoretical = mu + 0.675 * sig\n",
      "print('theoretical IQR: ',lower_theoretical, upper_theoretical)\n",
      "data = sig * np.random.standard_normal(1000) + mu\n",
      "lower, upper = np.percentile(data, [25, 75])\n",
      "print('IQR of data ', lower, upper)\n",
      "plt.hist(data, bins=20, cumulative=True, histtype='step')\n",
      "plt.axvline(lower, color='r')\n",
      "plt.axvline(upper, color='r')\n",
      "plt.axvline(lower_theoretical, color='k')\n",
      "plt.axvline(upper_theoretical, color='k')\n",
      "plt.xlabel('bins')\n",
      "plt.ylabel('cumulative number of data points')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back2\">Back to Exercise 2</a>\n",
      "\n",
      "<a name=\"ex3answer\">Answers to Exercise 3</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "data = pd.read_table('../data/verified_pb.data', names=['gender', 'speaker', 'pid', 'phoneme', 'F0', 'F1', 'F2', 'F3'])\n",
      "data.head()\n",
      "\n",
      "print 'min and max F0: ', np.amin(data.F0), np.amax(data.F0)\n",
      "print 'mean and std of F1: ', np.mean(data.F1), np.std(data.F1)\n",
      "print '2.5%, 50%, 97.5% F3: ', np.percentile(data.F3, [2.5, 50, 97.5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back3\">Back to Exercise 3</a>\n",
      "\n",
      "<a name=\"ex4answer\">Answers to Exercise 4</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Mean of F0: ', data.F0.mean())\n",
      "print('Std of F0: ', data.F0.std())\n",
      "bp = plt.boxplot(data.F0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Mean of F0: ', data.F0[data.gender==1].mean())\n",
      "print('Std of F0: ', data.F0[data.gender==1].std())\n",
      "bp = plt.boxplot(data.F0[data.gender==1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F0 = data.F0[data.gender==1]\n",
      "bp = plt.boxplot(F0[F0 < 165])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back4\">Back to Exercise 4</a>\n",
      "\n",
      "<a name=\"ex5answer\">Answers to Exercise 5</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(data.F0, bins=50)\n",
      "ph = plt.xlabel('F0 (Hz)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back5\">Back to Exercise 5</a>\n",
      "\n",
      "<a name=\"ex6answer\">Answers to Exercise 6</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm\n",
      "plt.hist(data.F0, bins=50, normed=True, color='gray')\n",
      "meanF0 = np.mean(data.F0)\n",
      "stdF0 = np.std(data.F0)\n",
      "x = np.linspace(np.amin(data.F0), np.amax(data.F0), 100)\n",
      "y = norm.pdf(x, loc=meanF0, scale=stdF0)\n",
      "ph = plt.plot(x, y, 'r')\n",
      "xlim = plt.gca().get_xlim()\n",
      "for gender in np.unique(data.gender):\n",
      "    plt.figure()\n",
      "    F0 = data.F0[data.gender==gender]\n",
      "    plt.hist(F0.values, bins=30, normed=True, color='gray', alpha=0.5)\n",
      "    plt.xlim(xlim)\n",
      "    meanF0 = np.mean(F0)\n",
      "    stdF0 = np.std(F0)\n",
      "    x = np.linspace(np.amin(F0), np.amax(F0), 100)\n",
      "    y = norm.pdf(x, loc=meanF0, scale=stdF0)\n",
      "    ph = plt.plot(x, y, 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back6\">Back to Exercise 6</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}